{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQAL57QiLOg3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import PredefinedSplit\n",
        "from xgboost import XGBRegressor\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# === Step 1: Load Data ===\n",
        "df = pd.read_csv(\"goup_project_sample_v3.csv\", parse_dates=[\"date\"])\n",
        "factors = pd.read_csv(\"factor_char_list.csv\")[\"variable\"].tolist()\n",
        "\n",
        "df[\"date\"] = df[\"date\"].dt.to_period(\"M\").dt.to_timestamp()\n",
        "\n",
        "# Compute EPS surprise\n",
        "eps_stdevest_adj = df[\"eps_stdevest\"].fillna(1e-6).replace(0, 1e-6)\n",
        "df[\"eps_surprise\"] = (df[\"eps_actual\"] - df[\"eps_meanest\"]) / eps_stdevest_adj\n",
        "df = df.dropna(subset=[\"eps_surprise\"] + factors)\n",
        "\n",
        "# === Step 2: Expanding Window with Bayesian Optimization ===\n",
        "results = []\n",
        "starting = pd.to_datetime(\"20000101\")\n",
        "counter = 0\n",
        "\n",
        "while (starting + pd.DateOffset(years=11 + counter)) <= pd.to_datetime(\"20240101\"):\n",
        "    cutoff = [\n",
        "        starting,\n",
        "        starting + pd.DateOffset(years=8 + counter),\n",
        "        starting + pd.DateOffset(years=10 + counter),\n",
        "        starting + pd.DateOffset(years=11 + counter)\n",
        "    ]\n",
        "\n",
        "    train = df[(df[\"date\"] >= cutoff[0]) & (df[\"date\"] < cutoff[1])]\n",
        "    val   = df[(df[\"date\"] >= cutoff[1]) & (df[\"date\"] < cutoff[2])]\n",
        "    test  = df[(df[\"date\"] >= cutoff[2]) & (df[\"date\"] < cutoff[3])]\n",
        "\n",
        "    if train.empty or val.empty or test.empty:\n",
        "        counter += 1\n",
        "        continue\n",
        "\n",
        "    # === Preprocessing ===\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(train[factors])\n",
        "    y_train = train[\"eps_surprise\"].values\n",
        "    X_val = scaler.transform(val[factors])\n",
        "    y_val = val[\"eps_surprise\"].values\n",
        "    X_test = scaler.transform(test[factors])\n",
        "    y_test = test[\"eps_surprise\"].values\n",
        "\n",
        "    # Combine for tuning\n",
        "    X_comb = np.vstack([X_train, X_val])\n",
        "    y_comb = np.concatenate([y_train, y_val])\n",
        "    split_idx = [-1] * len(X_train) + [0] * len(X_val)\n",
        "    ps = PredefinedSplit(test_fold=split_idx)\n",
        "\n",
        "    # === Bayesian Optimization ===\n",
        "    bayes_cv = BayesSearchCV(\n",
        "        XGBRegressor(objective=\"reg:squarederror\", random_state=42, n_jobs=-1),\n",
        "        search_spaces={\n",
        "            'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
        "            'max_depth': Integer(3, 7),\n",
        "            'subsample': Real(0.5, 1.0),\n",
        "            'colsample_bytree': Real(0.5, 1.0),\n",
        "            'n_estimators': Integer(50, 300),\n",
        "        },\n",
        "        n_iter=20,\n",
        "        scoring='neg_mean_squared_error',\n",
        "        cv=ps,\n",
        "        refit=True,\n",
        "        random_state=42,\n",
        "        verbose=0\n",
        "    )\n",
        "    bayes_cv.fit(X_comb, y_comb)\n",
        "    model = bayes_cv.best_estimator_\n",
        "\n",
        "    # === Predict and store ===\n",
        "    test_pred = model.predict(X_test)\n",
        "    temp_df = test[[\"permno\", \"date\"]].copy()\n",
        "    temp_df[\"actual\"] = y_test\n",
        "    temp_df[\"pred\"] = test_pred\n",
        "    results.append(temp_df)\n",
        "\n",
        "    print(f\"✅ Window {counter + 1} — Best params: {bayes_cv.best_params_}\")\n",
        "    counter += 1\n",
        "\n",
        "# === Step 3: Evaluate OOS R² ===\n",
        "df_eval = pd.concat(results).dropna()\n",
        "y_true = df_eval[\"actual\"].values\n",
        "y_pred = df_eval[\"pred\"].values\n",
        "\n",
        "numerator = np.sum((y_true - y_pred) ** 2)\n",
        "denominator = np.sum((y_true - np.mean(y_true)) ** 2)\n",
        "oos_r2 = 1 - numerator / denominator\n",
        "\n",
        "print(f\"\\n✅ EPS Surprise — OOS R² (vs mean): {oos_r2:.4%}\")\n",
        "\n"
      ]
    }
  ]
}