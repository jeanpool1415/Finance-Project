{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPCA EARNINGS SURPRISE PREDICTION\n",
      "==================================================\n",
      "Loaded data: 911537 observations, 165 features\n",
      "Earnings surprise distribution:\n",
      "earnings_surprise\n",
      "1.0    310507\n",
      "NaN    307811\n",
      "0.0    293219\n",
      "Name: count, dtype: int64\n",
      "Using 148 characteristic variables for IPCA\n",
      "\n",
      "==================================================\n",
      "SELECTING OPTIMAL NUMBER OF FACTORS (K)\n",
      "==================================================\n",
      "\n",
      "Testing K = 4...\n",
      "Data after filtering: 403294 observations\n",
      "Using 295 dates with sufficient cross-section\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from ipca_classes_update import IPCA_v1\n",
    "import warnings\n",
    "from xgboost import XGBClassifier\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def prepare_earnings_surprise_data(filepath):\n",
    "    \"\"\"\n",
    "    Load and prepare data for earnings surprise prediction using IPCA\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data = pd.read_csv(filepath)\n",
    "    print(f\"Loaded data: {data.shape[0]} observations, {data.shape[1]} features\")\n",
    "    \n",
    "    # Create date column and sort\n",
    "    data['date'] = pd.to_datetime(data[['year', 'month']].assign(day=1))\n",
    "    data = data.sort_values(['date', 'permno']).reset_index(drop=True)\n",
    "    \n",
    "    # Create earnings surprise binary target\n",
    "    # 1 if actual EPS > median estimate, 0 otherwise\n",
    "    data['earnings_surprise'] = np.where(\n",
    "        (data['eps_actual'].notna()) & (data['eps_medest'].notna()),\n",
    "        (data['eps_actual'] > data['eps_medest']).astype(int),\n",
    "        np.nan\n",
    "    )\n",
    "    \n",
    "    print(f\"Earnings surprise distribution:\")\n",
    "    print(data['earnings_surprise'].value_counts(dropna=False))\n",
    "    \n",
    "    # Define characteristic variables (excluding forward-looking and identifiers)\n",
    "    exclude_vars = [\n",
    "        # Target/forward-looking variables\n",
    "        'ret_eom', 'stock_exret', 'earnings_surprise',\n",
    "        'eps_medest', 'eps_meanest', 'eps_stdevest', 'eps_actual',\n",
    "        \n",
    "        # Identifiers and date variables\n",
    "        'permno', 'CUSIP', 'stock_ticker', 'comp_name', \n",
    "        'year', 'month', 'date', 'SHRCD', 'EXCHCD',\n",
    "        \n",
    "        # Market-wide variables\n",
    "        'RF', 'size_port'\n",
    "    ]\n",
    "    \n",
    "    # Get characteristic variables\n",
    "    char_vars = [col for col in data.columns if col not in exclude_vars]\n",
    "    print(f\"Using {len(char_vars)} characteristic variables for IPCA\")\n",
    "    \n",
    "    return data, char_vars\n",
    "\n",
    "def run_ipca_earnings_prediction(data, char_vars, K=6, min_obs_per_date=50, \n",
    "                                oos_start_year=2010, oos_window=60):\n",
    "    \"\"\"\n",
    "    Run IPCA analysis for earnings surprise prediction\n",
    "    \"\"\"\n",
    "    # Filter data with valid earnings surprise and sufficient characteristics\n",
    "    valid_data = data.dropna(subset=['earnings_surprise'] + char_vars[:20])  # Require at least 20 non-missing chars\n",
    "    print(f\"Data after filtering: {valid_data.shape[0]} observations\")\n",
    "    \n",
    "    # Filter dates with sufficient cross-section\n",
    "    date_counts = valid_data.groupby('date').size()\n",
    "    valid_dates = date_counts[date_counts >= min_obs_per_date].index\n",
    "    valid_data = valid_data[valid_data['date'].isin(valid_dates)]\n",
    "    print(f\"Using {len(valid_dates)} dates with sufficient cross-section\")\n",
    "    \n",
    "    # Create multi-index dataset for IPCA\n",
    "    ipca_data = valid_data.set_index(['date', 'permno'])[['earnings_surprise'] + char_vars]\n",
    "    \n",
    "    # Handle missing values by forward-filling within each stock\n",
    "    ipca_data = ipca_data.groupby(level=1).fillna(method='ffill')\n",
    "    \n",
    "    # Rank transform characteristics to [-0.5, 0.5] by date\n",
    "    char_data = ipca_data[char_vars].copy()\n",
    "    for date in char_data.index.get_level_values(0).unique():\n",
    "        date_mask = char_data.index.get_level_values(0) == date\n",
    "        for var in char_vars:\n",
    "            if char_data.loc[date_mask, var].notna().sum() > 10:  # Sufficient non-missing\n",
    "                ranks = char_data.loc[date_mask, var].rank(method='dense') - 1\n",
    "                max_rank = ranks.max()\n",
    "                if max_rank > 0:\n",
    "                    char_data.loc[date_mask, var] = (ranks / max_rank) - 0.5\n",
    "                else:\n",
    "                    char_data.loc[date_mask, var] = 0\n",
    "    \n",
    "    # Combine target with transformed characteristics\n",
    "    ipca_input = pd.concat([ipca_data[['earnings_surprise']], char_data], axis=1)\n",
    "    ipca_input = ipca_input.dropna()\n",
    "    \n",
    "    print(f\"Final IPCA dataset: {ipca_input.shape[0]} observations\")\n",
    "    \n",
    "    # Initialize IPCA\n",
    "    ipca = IPCA_v1(ipca_input, return_column='earnings_surprise', add_constant=True)\n",
    "    \n",
    "    # Split data for OOS analysis\n",
    "    oos_dates = ipca_input.index.get_level_values(0) >= pd.to_datetime(f'{oos_start_year}-01-01')\n",
    "    \n",
    "    if oos_dates.sum() > 0:\n",
    "        print(\"Running out-of-sample IPCA estimation...\")\n",
    "        # Out-of-sample estimation\n",
    "        results = ipca.fit(\n",
    "            K=K, \n",
    "            OOS=True, \n",
    "            OOS_window='recursive', \n",
    "            OOS_window_specs=oos_window,\n",
    "            R_fit=True,\n",
    "            dispIters=True,\n",
    "            dispItersInt=50\n",
    "        )\n",
    "    else:\n",
    "        print(\"Running in-sample IPCA estimation...\")\n",
    "        # In-sample estimation\n",
    "        results = ipca.fit(K=K, R_fit=True, dispIters=True)\n",
    "    \n",
    "    return results, ipca, ipca_input\n",
    "\n",
    "def select_optimal_k(data, char_vars, k_range=range(4, 16), \n",
    "                    min_obs_per_date=100, oos_start_year=2010, oos_window=60):\n",
    "    \"\"\"\n",
    "    Select optimal number of factors K using cross-validation\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SELECTING OPTIMAL NUMBER OF FACTORS (K)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    k_results = {}\n",
    "    \n",
    "    for k in k_range:\n",
    "        print(f\"\\nTesting K = {k}...\")\n",
    "        try:\n",
    "            # Run IPCA with current K\n",
    "            results, ipca, ipca_input_k = run_ipca_earnings_prediction(\n",
    "                data, char_vars, K=k, min_obs_per_date=min_obs_per_date,\n",
    "                oos_start_year=oos_start_year, oos_window=oos_window\n",
    "            )\n",
    "            \n",
    "            # Quick evaluation\n",
    "            prediction_results = evaluate_ipca_factors_for_prediction(\n",
    "                results, ipca_input_k, ipca, K=k, verbose=False\n",
    "            )\n",
    "            \n",
    "            if prediction_results and 'metrics' in prediction_results:\n",
    "                auc = prediction_results['metrics']['auc']\n",
    "                r2_managed = results['xfits']['R2_Total']\n",
    "                r2_returns = results['rfits']['R2_Total']\n",
    "                \n",
    "                k_results[k] = {\n",
    "                    'auc': auc,\n",
    "                    'r2_managed': r2_managed,\n",
    "                    'r2_returns': r2_returns,\n",
    "                    'score': auc  # Primary metric for selection\n",
    "                }\n",
    "                \n",
    "                print(f\"  AUC: {auc:.3f}, R²(managed): {r2_managed:.3f}, R²(returns): {r2_returns:.3f}\")\n",
    "            else:\n",
    "                k_results[k] = {'auc': 0, 'r2_managed': 0, 'r2_returns': 0, 'score': 0}\n",
    "                print(f\"  Failed to evaluate K={k}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  Error with K={k}: {str(e)}\")\n",
    "            k_results[k] = {'auc': 0, 'r2_managed': 0, 'r2_returns': 0, 'score': 0}\n",
    "    \n",
    "    # Find optimal K\n",
    "    if k_results:\n",
    "        optimal_k = max(k_results.keys(), key=lambda x: k_results[x]['score'])\n",
    "        \n",
    "        print(f\"\\n\" + \"=\"*30)\n",
    "        print(\"K SELECTION RESULTS:\")\n",
    "        print(\"=\"*30)\n",
    "        for k in sorted(k_results.keys()):\n",
    "            metrics = k_results[k]\n",
    "            marker = \" ← OPTIMAL\" if k == optimal_k else \"\"\n",
    "            print(f\"K={k:2d}: AUC={metrics['auc']:.3f}, R²(mgd)={metrics['r2_managed']:.3f}, R²(ret)={metrics['r2_returns']:.3f}{marker}\")\n",
    "        \n",
    "        print(f\"\\nSelected optimal K = {optimal_k}\")\n",
    "        return optimal_k, k_results\n",
    "    else:\n",
    "        print(\"No valid results found, defaulting to K=6\")\n",
    "        return 6, {}\n",
    "\n",
    "def evaluate_ipca_factors_for_prediction(results, ipca_input, ipca, K=6, verbose=True):\n",
    "    \"\"\"\n",
    "    Use IPCA factors to predict earnings surprise\n",
    "    \"\"\"\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"EVALUATING IPCA FACTORS FOR EARNINGS PREDICTION\")\n",
    "        print(\"=\"*50)\n",
    "    \n",
    "    # Extract factor loadings and create factor scores\n",
    "    gamma = results['Gamma']\n",
    "    if isinstance(gamma.index, pd.MultiIndex):\n",
    "        # OOS case - use latest Gamma\n",
    "        latest_date = gamma.index.get_level_values(0).max()\n",
    "        gamma_final = gamma.loc[latest_date]\n",
    "    else:\n",
    "        # In-sample case\n",
    "        gamma_final = gamma\n",
    "    \n",
    "    print(f\"Factor loadings shape: {gamma_final.shape}\")\n",
    "    if verbose:\n",
    "        print(f\"Top characteristics for each factor:\")\n",
    "        for i in range(min(K, gamma_final.shape[1])):\n",
    "            factor_name = gamma_final.columns[i]\n",
    "            top_chars = gamma_final.iloc[:, i].abs().nlargest(5)\n",
    "            print(f\"\\nFactor {factor_name}:\")\n",
    "            for char, loading in top_chars.items():\n",
    "                print(f\"  {char}: {loading:.3f}\")\n",
    "    \n",
    "    # Create factor scores for prediction\n",
    "    char_vars = gamma_final.index.tolist()\n",
    "    if 'Constant' in char_vars:\n",
    "        char_vars.remove('Constant')\n",
    "    \n",
    "    # Calculate factor scores\n",
    "    factor_scores_list = []\n",
    "    \n",
    "    for date in ipca_input.index.get_level_values(0).unique():\n",
    "        date_data = ipca_input.loc[date]\n",
    "        if date_data.shape[0] > 10:  # Sufficient observations\n",
    "            # Get characteristics matrix\n",
    "            X = date_data[char_vars].values\n",
    "            # Add constant\n",
    "            X_with_const = np.column_stack([X, np.ones(X.shape[0])])\n",
    "            \n",
    "            # Calculate factor scores\n",
    "            factor_scores = X_with_const @ gamma_final.values\n",
    "            \n",
    "            # Create DataFrame\n",
    "            factor_df = pd.DataFrame(\n",
    "                factor_scores, \n",
    "                index=date_data.index,\n",
    "                columns=gamma_final.columns\n",
    "            )\n",
    "            factor_df['date'] = date\n",
    "            factor_df['earnings_surprise'] = date_data['earnings_surprise'].values\n",
    "            factor_scores_list.append(factor_df)\n",
    "    \n",
    "    if len(factor_scores_list) == 0:\n",
    "        if verbose:\n",
    "            print(\"No valid data for factor score calculation\")\n",
    "        return None\n",
    "    \n",
    "    # Combine all factor scores\n",
    "    all_factor_scores = pd.concat(factor_scores_list, ignore_index=True)\n",
    "    all_factor_scores = all_factor_scores.dropna()\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nFactor scores dataset: {all_factor_scores.shape[0]} observations\")\n",
    "    \n",
    "    # Split into train/test\n",
    "    train_data = all_factor_scores[all_factor_scores['date'] < pd.to_datetime('2015-01-01')]\n",
    "    test_data = all_factor_scores[all_factor_scores['date'] >= pd.to_datetime('2015-01-01')]\n",
    "    \n",
    "    if len(train_data) == 0 or len(test_data) == 0:\n",
    "        if verbose:\n",
    "            print(\"Insufficient data for train/test split\")\n",
    "        return all_factor_scores\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Train set: {len(train_data)} observations\")\n",
    "        print(f\"Test set: {len(test_data)} observations\")\n",
    "    \n",
    "    # Prepare features (exclude date and target)\n",
    "    factor_cols = gamma_final.columns.tolist()\n",
    "    X_train = train_data[factor_cols]\n",
    "    y_train = train_data['earnings_surprise']\n",
    "    X_test = test_data[factor_cols]\n",
    "    y_test = test_data['earnings_surprise']\n",
    "    \n",
    "    # Train logistic regression\n",
    "# With this:\n",
    "    xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred_proba = xgb.predict_proba(X_test)[:, 1]\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    # Evaluate\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nPREDICTION RESULTS:\")\n",
    "        print(f\"Accuracy: {accuracy:.3f}\")\n",
    "        print(f\"Precision: {precision:.3f}\")\n",
    "        print(f\"Recall: {recall:.3f}\")\n",
    "        print(f\"F1-Score: {f1:.3f}\")\n",
    "        print(f\"AUC-ROC: {auc:.3f}\")\n",
    "        \n",
    "        # Feature importance\n",
    "        print(f\"\\nFACTOR IMPORTANCE (Logistic Regression Coefficients):\")\n",
    "        for factor, coef in zip(factor_cols, lr.coef_[0]):\n",
    "            print(f\"{factor}: {coef:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'factor_scores': all_factor_scores,\n",
    "        'gamma': gamma_final,\n",
    "        'model': lr,\n",
    "        'metrics': {\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'auc': auc\n",
    "        }\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main execution function\n",
    "    \"\"\"\n",
    "    print(\"IPCA EARNINGS SURPRISE PREDICTION\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Load and prepare data\n",
    "    filepath = '/teamspace/studios/this_studio/goup_project_sample_v3.csv'  # Replace with your actual file path\n",
    "    data, char_vars = prepare_earnings_surprise_data(filepath)\n",
    "    \n",
    "    # Select optimal K\n",
    "    optimal_k, k_results = select_optimal_k(\n",
    "        data, char_vars,\n",
    "        k_range=range(4, 16),  # Test K from 4 to 15\n",
    "        min_obs_per_date=100,\n",
    "        oos_start_year=2012,\n",
    "        oos_window=60\n",
    "    )\n",
    "    \n",
    "    # Run IPCA analysis with optimal K\n",
    "    print(f\"\\nRunning final analysis with K = {optimal_k}...\")\n",
    "    results, ipca, ipca_input = run_ipca_earnings_prediction(\n",
    "        data, char_vars, \n",
    "        K=optimal_k,\n",
    "        min_obs_per_date=100,\n",
    "        oos_start_year=2012,\n",
    "        oos_window=60\n",
    "    )\n",
    "    \n",
    "    # Print IPCA results\n",
    "    print(f\"\\nFINAL IPCA ESTIMATION RESULTS (K={optimal_k}):\")\n",
    "    print(f\"Managed Portfolio R²: {results['xfits']['R2_Total']:.3f}\")\n",
    "    print(f\"Returns R²: {results['rfits']['R2_Total']:.3f}\")\n",
    "    \n",
    "    # Detailed evaluation with optimal K\n",
    "    prediction_results = evaluate_ipca_factors_for_prediction(\n",
    "        results, ipca_input, ipca, K=optimal_k, verbose=True\n",
    "    )\n",
    "    \n",
    "    if prediction_results:\n",
    "        # Save results\n",
    "        prediction_results['factor_scores'].to_csv('ipca_factor_scores.csv', index=False)\n",
    "        results['Gamma'].to_csv('ipca_factor_loadings.csv')\n",
    "        \n",
    "        # Save K selection results\n",
    "        k_results_df = pd.DataFrame(k_results).T\n",
    "        k_results_df.to_csv('k_selection_results.csv')\n",
    "        \n",
    "        print(f\"\\nResults saved:\")\n",
    "        print(f\"- Factor scores: ipca_factor_scores.csv\")\n",
    "        print(f\"- Factor loadings: ipca_factor_loadings.csv\") \n",
    "        print(f\"- K selection results: k_selection_results.csv\")\n",
    "        print(f\"- Optimal K used: {optimal_k}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
